namespace: grafana-stack

alloy:
  alloy:
    # We need hostPath mounts to read /var/log/containers/*.log for filelog receiver:
    mounts:
      varlog: true
      dockercontainers: true

    configMap:
      create: true
      content: |-
        extension "health_check" {
          endpoint = "0.0.0.0:13133"
        }

        extension "pprof" {}
        extension "zpages" {}

        otelcol.receiver.otlp "otlp_in" {
          grpc {
            endpoint = "0.0.0.0:4317"
          }
          http {
            endpoint = "0.0.0.0:4318"
          }

          output {
            logs    = [processor.batch.main.input]
            metrics = [processor.batch.main.input]
            traces  = [processor.batch.main.input]
          }
        }

        otelcol.receiver.filelog "k8s_logs" {
          include = [
            "/var/log/containers/*.log",
          ]
          start_at = "beginning"

          operators {
            json_parser {
              parse_to       = "body"
              timestamp_from = "body.time"
            }
          }

          output {
            logs = [processor.k8sattrs.logs.input]
          }
        }

        prometheus.discovery.kubernetes "cluster_sd" {
          output = ["prometheus.scrape.cluster.input"]
        }

        prometheus.scrape "cluster" {
          forward_to = [processor.batch.main.metrics.input]

          wal_directory = "/tmp/agent/wal_prometheus"
        }

        otelcol.processor.k8sattributes "k8sattrs" {
          auth_type = "serviceAccount"

          extract {
            container = "container_name"
            namespace = "namespace_name"
            pod       = "pod_name"
          }
          output {
            logs = [processor.memory_limiter.logs.input]
          }
        }

        otelcol.processor.memory_limiter "memory_limiter" {
          check_interval         = "1s"
          limit_percentage       = 70
          spike_limit_percentage = 20
          output {
            logs    = [processor.retry.logs.input]
            metrics = [processor.retry.metrics.input]
            traces  = [processor.retry.traces.input]
          }
        }

        otelcol.processor.retry "retry" {
          output {
            logs    = [processor.batch.main.logs.input]
            metrics = [processor.batch.main.metrics.input]
            traces  = [processor.batch.main.traces.input]
          }
        }

        otelcol.processor.batch "main" {
          send_batch_size    = 1024
          send_batch_max_size = 2048
          timeout            = "10s"

          output {
            logs    = [
              loki.write.incluster.input,
            ]
            metrics = [
              prometheus.remote_write.incluster.input,
            ]
            traces  = [
              otelcol.exporter.otlp.tempo_out.input,
            ]
          }
        }

        loki.write "incluster" {
          endpoint {
            url = "http://loki.grafana-stack.svc.cluster.local:3100/loki/api/v1/push"
          }
        }

        otelcol.exporter.otlp "tempo_out" {
          client {
            endpoint = "tempo.grafana-stack.svc.cluster.local:4317"
            tls {
              insecure = true
            }
          }
        }

        prometheus.remote_write "incluster" {
          endpoint {
            url = "http://kube-prometheus-stack-prometheus.kube-prometheus-stack.svc.cluster.local:9090/api/v1/write"
          }
        }

        service "default" {
          extensions = [
            "health_check",
            "pprof",
            "zpages",
          ]

          pipelines = {
          }
        }
    resources:
      requests:
        memory: 512Mi
        cpu: 250m
      limits:
        memory: 2Gi
        cpu: 1000m

  controller:
    type: 'daemonset'
#    replicas: 2
#    nodeSelector: {}
#    tolerations: []
#    affinity: {}

    # Provide any environment variables or secrets for extra config
#    extraEnv: []
      # - name: EXAMPLE_ENV
    #   value: "some_value"

    # If you want to pass environment variables from a secret:
    # envFrom:
    #   - secretRef:
    #       name: my-secrets

  configReloader:
    enabled: true  # automatically reload Flow config on ConfigMap changes

  service:
    # The chart will create a Service on the default Alloy port (12345).
    # This might not be strictly necessary if you only do local usage,
    # but you can enable it to have a stable DNS name or add an Ingress.
    enabled: true
    type: ClusterIP
